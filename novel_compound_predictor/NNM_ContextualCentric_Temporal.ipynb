{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook dealing with the final preprocessing steps for the neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import argparse\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "import pickle as pkl\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "import glob\n",
    "import random\n",
    "random.seed(1991)\n",
    "#torch.set_default_tensor_type('torch.cuda.DoubleTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1991)\n",
    "if not torch.cuda.is_available():\n",
    "    \n",
    "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 53466 entries, a_n to zygote_n\n",
      "Columns: 300 entries, 0 to 299\n",
      "dtypes: float64(300)\n",
      "memory usage: 122.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_n</th>\n",
       "      <td>0.536217</td>\n",
       "      <td>-0.029517</td>\n",
       "      <td>-0.012247</td>\n",
       "      <td>-0.020589</td>\n",
       "      <td>-0.024528</td>\n",
       "      <td>0.199687</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>-0.028174</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>-0.162900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058662</td>\n",
       "      <td>0.042939</td>\n",
       "      <td>0.032226</td>\n",
       "      <td>0.045636</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.061979</td>\n",
       "      <td>0.025265</td>\n",
       "      <td>0.032431</td>\n",
       "      <td>0.010333</td>\n",
       "      <td>-0.068106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa_n</th>\n",
       "      <td>0.016471</td>\n",
       "      <td>-0.002655</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>-0.001233</td>\n",
       "      <td>0.027962</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>-0.006771</td>\n",
       "      <td>0.005269</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005486</td>\n",
       "      <td>0.081462</td>\n",
       "      <td>0.044021</td>\n",
       "      <td>0.055576</td>\n",
       "      <td>-0.031826</td>\n",
       "      <td>0.043881</td>\n",
       "      <td>0.017116</td>\n",
       "      <td>-0.012633</td>\n",
       "      <td>-0.003582</td>\n",
       "      <td>-0.070446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa_n</th>\n",
       "      <td>0.369783</td>\n",
       "      <td>-0.008786</td>\n",
       "      <td>-0.033639</td>\n",
       "      <td>-0.011358</td>\n",
       "      <td>-0.021063</td>\n",
       "      <td>0.152685</td>\n",
       "      <td>-0.001936</td>\n",
       "      <td>-0.020756</td>\n",
       "      <td>0.049742</td>\n",
       "      <td>-0.122735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036469</td>\n",
       "      <td>0.041279</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.026513</td>\n",
       "      <td>-0.033482</td>\n",
       "      <td>0.040557</td>\n",
       "      <td>0.026827</td>\n",
       "      <td>0.034848</td>\n",
       "      <td>-0.025072</td>\n",
       "      <td>-0.068561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaa_n</th>\n",
       "      <td>0.001559</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>-0.000796</td>\n",
       "      <td>0.004964</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>-0.007268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063368</td>\n",
       "      <td>0.120493</td>\n",
       "      <td>0.037918</td>\n",
       "      <td>0.045026</td>\n",
       "      <td>-0.030933</td>\n",
       "      <td>0.076486</td>\n",
       "      <td>0.060778</td>\n",
       "      <td>0.095964</td>\n",
       "      <td>-0.030948</td>\n",
       "      <td>-0.158763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaai_n</th>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.010847</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.031081</td>\n",
       "      <td>-0.002763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005658</td>\n",
       "      <td>-0.004508</td>\n",
       "      <td>-0.002646</td>\n",
       "      <td>-0.020482</td>\n",
       "      <td>0.093074</td>\n",
       "      <td>0.036829</td>\n",
       "      <td>0.048474</td>\n",
       "      <td>-0.106865</td>\n",
       "      <td>-0.014324</td>\n",
       "      <td>-0.063920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6    \\\n",
       "head                                                                            \n",
       "a_n      0.536217 -0.029517 -0.012247 -0.020589 -0.024528  0.199687  0.002459   \n",
       "aa_n     0.016471 -0.002655  0.003908  0.000666 -0.001233  0.027962  0.000181   \n",
       "aaa_n    0.369783 -0.008786 -0.033639 -0.011358 -0.021063  0.152685 -0.001936   \n",
       "aaaaa_n  0.001559 -0.000158  0.000625  0.000832 -0.000796  0.004964  0.000146   \n",
       "aaai_n   0.000988  0.000103  0.001039  0.002720 -0.000062  0.001140  0.010847   \n",
       "\n",
       "              7         8         9    ...       290       291       292  \\\n",
       "head                                   ...                                 \n",
       "a_n     -0.028174  0.000748 -0.162900  ... -0.058662  0.042939  0.032226   \n",
       "aa_n    -0.006771  0.005269  0.002151  ... -0.005486  0.081462  0.044021   \n",
       "aaa_n   -0.020756  0.049742 -0.122735  ... -0.036469  0.041279  0.011177   \n",
       "aaaaa_n -0.000465  0.002441 -0.007268  ... -0.063368  0.120493  0.037918   \n",
       "aaai_n   0.000047  0.031081 -0.002763  ...  0.005658 -0.004508 -0.002646   \n",
       "\n",
       "              293       294       295       296       297       298       299  \n",
       "head                                                                           \n",
       "a_n      0.045636  0.000804  0.061979  0.025265  0.032431  0.010333 -0.068106  \n",
       "aa_n     0.055576 -0.031826  0.043881  0.017116 -0.012633 -0.003582 -0.070446  \n",
       "aaa_n    0.026513 -0.033482  0.040557  0.026827  0.034848 -0.025072 -0.068561  \n",
       "aaaaa_n  0.045026 -0.030933  0.076486  0.060778  0.095964 -0.030948 -0.158763  \n",
       "aaai_n  -0.020482  0.093074  0.036829  0.048474 -0.106865 -0.014324 -0.063920  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heads=pd.read_pickle(\"/data/dharp/compounding/datasets/heads_CompoundCentric_DecadeCentric_300.pkl\")\n",
    "heads.reset_index(inplace=True)\n",
    "heads=heads.drop(['decade'],axis=1).groupby(['head']).mean()\n",
    "heads.info()\n",
    "heads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 54400 entries, a_n to zylobalsamum_n\n",
      "Columns: 300 entries, 0 to 299\n",
      "dtypes: float64(300)\n",
      "memory usage: 124.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_n</th>\n",
       "      <td>0.250488</td>\n",
       "      <td>-0.016303</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>-0.030004</td>\n",
       "      <td>0.080336</td>\n",
       "      <td>-0.005189</td>\n",
       "      <td>-0.011844</td>\n",
       "      <td>0.024295</td>\n",
       "      <td>-0.076888</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009632</td>\n",
       "      <td>0.081663</td>\n",
       "      <td>0.058108</td>\n",
       "      <td>0.024490</td>\n",
       "      <td>-0.053609</td>\n",
       "      <td>-0.097451</td>\n",
       "      <td>0.093379</td>\n",
       "      <td>-0.004846</td>\n",
       "      <td>-0.065470</td>\n",
       "      <td>-0.238026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa_n</th>\n",
       "      <td>0.068528</td>\n",
       "      <td>-0.004179</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>-0.001845</td>\n",
       "      <td>-0.002256</td>\n",
       "      <td>0.015144</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>-0.004580</td>\n",
       "      <td>0.004887</td>\n",
       "      <td>-0.023613</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059578</td>\n",
       "      <td>0.108445</td>\n",
       "      <td>0.028685</td>\n",
       "      <td>0.041453</td>\n",
       "      <td>-0.016382</td>\n",
       "      <td>0.060577</td>\n",
       "      <td>0.060166</td>\n",
       "      <td>0.083766</td>\n",
       "      <td>-0.017441</td>\n",
       "      <td>-0.146023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa_n</th>\n",
       "      <td>0.021914</td>\n",
       "      <td>-0.002406</td>\n",
       "      <td>0.011616</td>\n",
       "      <td>0.023197</td>\n",
       "      <td>-0.009332</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>-0.001105</td>\n",
       "      <td>0.002711</td>\n",
       "      <td>-0.008170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058486</td>\n",
       "      <td>0.114269</td>\n",
       "      <td>0.047182</td>\n",
       "      <td>0.046012</td>\n",
       "      <td>-0.032943</td>\n",
       "      <td>0.074439</td>\n",
       "      <td>0.064875</td>\n",
       "      <td>0.087735</td>\n",
       "      <td>-0.028544</td>\n",
       "      <td>-0.159535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaa_n</th>\n",
       "      <td>0.001559</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>-0.000796</td>\n",
       "      <td>0.004964</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>-0.007268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063368</td>\n",
       "      <td>0.120493</td>\n",
       "      <td>0.037918</td>\n",
       "      <td>0.045026</td>\n",
       "      <td>-0.030933</td>\n",
       "      <td>0.076486</td>\n",
       "      <td>0.060778</td>\n",
       "      <td>0.095964</td>\n",
       "      <td>-0.030948</td>\n",
       "      <td>-0.158763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaa_n</th>\n",
       "      <td>0.001559</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>-0.000796</td>\n",
       "      <td>0.004964</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>-0.007268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063368</td>\n",
       "      <td>0.120493</td>\n",
       "      <td>0.037918</td>\n",
       "      <td>0.045026</td>\n",
       "      <td>-0.030933</td>\n",
       "      <td>0.076486</td>\n",
       "      <td>0.060778</td>\n",
       "      <td>0.095964</td>\n",
       "      <td>-0.030948</td>\n",
       "      <td>-0.158763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5    \\\n",
       "modifier                                                               \n",
       "a_n       0.250488 -0.016303  0.002421  0.044242 -0.030004  0.080336   \n",
       "aa_n      0.068528 -0.004179  0.002100 -0.001845 -0.002256  0.015144   \n",
       "aaa_n     0.021914 -0.002406  0.011616  0.023197 -0.009332  0.002951   \n",
       "aaaa_n    0.001559 -0.000158  0.000625  0.000832 -0.000796  0.004964   \n",
       "aaaaa_n   0.001559 -0.000158  0.000625  0.000832 -0.000796  0.004964   \n",
       "\n",
       "               6         7         8         9    ...       290       291  \\\n",
       "modifier                                          ...                       \n",
       "a_n      -0.005189 -0.011844  0.024295 -0.076888  ... -0.009632  0.081663   \n",
       "aa_n      0.007321 -0.004580  0.004887 -0.023613  ... -0.059578  0.108445   \n",
       "aaa_n     0.000239 -0.001105  0.002711 -0.008170  ... -0.058486  0.114269   \n",
       "aaaa_n    0.000146 -0.000465  0.002441 -0.007268  ... -0.063368  0.120493   \n",
       "aaaaa_n   0.000146 -0.000465  0.002441 -0.007268  ... -0.063368  0.120493   \n",
       "\n",
       "               292       293       294       295       296       297  \\\n",
       "modifier                                                               \n",
       "a_n       0.058108  0.024490 -0.053609 -0.097451  0.093379 -0.004846   \n",
       "aa_n      0.028685  0.041453 -0.016382  0.060577  0.060166  0.083766   \n",
       "aaa_n     0.047182  0.046012 -0.032943  0.074439  0.064875  0.087735   \n",
       "aaaa_n    0.037918  0.045026 -0.030933  0.076486  0.060778  0.095964   \n",
       "aaaaa_n   0.037918  0.045026 -0.030933  0.076486  0.060778  0.095964   \n",
       "\n",
       "               298       299  \n",
       "modifier                      \n",
       "a_n      -0.065470 -0.238026  \n",
       "aa_n     -0.017441 -0.146023  \n",
       "aaa_n    -0.028544 -0.159535  \n",
       "aaaa_n   -0.030948 -0.158763  \n",
       "aaaaa_n  -0.030948 -0.158763  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modifiers=pd.read_pickle(\"/data/dharp/compounding/datasets/modifiers_CompoundCentric_DecadeCentric_300.pkl\")\n",
    "modifiers.reset_index(inplace=True)\n",
    "modifiers=modifiers.drop(['decade'],axis=1).groupby(['modifier']).mean()\n",
    "modifiers.info()\n",
    "modifiers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_compounds_list = pkl.load( open( \"/data/dharp/compounding/datasets/novel_compounds_list.pkl\", \"rb\" ) )\n",
    "m, h = zip(*novel_compounds_list)\n",
    "heads_list=list(set(h))\n",
    "modifiers_list=list(set(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_compounds=pd.DataFrame(novel_compounds_list)\n",
    "novel_compounds.columns=['modifier','head']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_heads=pd.merge(novel_compounds.drop('modifier',axis=1),heads.reset_index(),on=[\"head\"])\n",
    "\n",
    "positive_modifiers=pd.merge(novel_compounds.drop('head',axis=1),modifiers.reset_index(),on=[\"modifier\"])\n",
    "#positive_df['Plausibility']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>peaceful_n</td>\n",
       "      <td>0.084673</td>\n",
       "      <td>0.004526</td>\n",
       "      <td>0.350015</td>\n",
       "      <td>-0.035577</td>\n",
       "      <td>0.021538</td>\n",
       "      <td>-0.047361</td>\n",
       "      <td>0.083481</td>\n",
       "      <td>-0.013165</td>\n",
       "      <td>0.014318</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008103</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.009874</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.006758</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>-0.007504</td>\n",
       "      <td>-0.003493</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.003710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>peaceful_n</td>\n",
       "      <td>0.084673</td>\n",
       "      <td>0.004526</td>\n",
       "      <td>0.350015</td>\n",
       "      <td>-0.035577</td>\n",
       "      <td>0.021538</td>\n",
       "      <td>-0.047361</td>\n",
       "      <td>0.083481</td>\n",
       "      <td>-0.013165</td>\n",
       "      <td>0.014318</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008103</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.009874</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.006758</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>-0.007504</td>\n",
       "      <td>-0.003493</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.003710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>robinson_n</td>\n",
       "      <td>0.690679</td>\n",
       "      <td>-0.055788</td>\n",
       "      <td>-0.069111</td>\n",
       "      <td>0.024073</td>\n",
       "      <td>-0.038583</td>\n",
       "      <td>0.038354</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>-0.009363</td>\n",
       "      <td>-0.038313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037275</td>\n",
       "      <td>-0.041498</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.018245</td>\n",
       "      <td>0.020412</td>\n",
       "      <td>0.019159</td>\n",
       "      <td>0.008809</td>\n",
       "      <td>-0.078762</td>\n",
       "      <td>-0.028517</td>\n",
       "      <td>-0.029286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>robinson_n</td>\n",
       "      <td>0.690679</td>\n",
       "      <td>-0.055788</td>\n",
       "      <td>-0.069111</td>\n",
       "      <td>0.024073</td>\n",
       "      <td>-0.038583</td>\n",
       "      <td>0.038354</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>-0.009363</td>\n",
       "      <td>-0.038313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037275</td>\n",
       "      <td>-0.041498</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.018245</td>\n",
       "      <td>0.020412</td>\n",
       "      <td>0.019159</td>\n",
       "      <td>0.008809</td>\n",
       "      <td>-0.078762</td>\n",
       "      <td>-0.028517</td>\n",
       "      <td>-0.029286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>supply_n</td>\n",
       "      <td>0.774867</td>\n",
       "      <td>-0.055282</td>\n",
       "      <td>-0.030543</td>\n",
       "      <td>-0.022465</td>\n",
       "      <td>-0.017167</td>\n",
       "      <td>0.228280</td>\n",
       "      <td>0.007839</td>\n",
       "      <td>-0.026089</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007130</td>\n",
       "      <td>0.042597</td>\n",
       "      <td>-0.007180</td>\n",
       "      <td>-0.007903</td>\n",
       "      <td>0.018143</td>\n",
       "      <td>0.023752</td>\n",
       "      <td>0.012634</td>\n",
       "      <td>-0.000541</td>\n",
       "      <td>-0.006356</td>\n",
       "      <td>0.012804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         head         0         1         2         3         4         5  \\\n",
       "0  peaceful_n  0.084673  0.004526  0.350015 -0.035577  0.021538 -0.047361   \n",
       "1  peaceful_n  0.084673  0.004526  0.350015 -0.035577  0.021538 -0.047361   \n",
       "2  robinson_n  0.690679 -0.055788 -0.069111  0.024073 -0.038583  0.038354   \n",
       "3  robinson_n  0.690679 -0.055788 -0.069111  0.024073 -0.038583  0.038354   \n",
       "4    supply_n  0.774867 -0.055282 -0.030543 -0.022465 -0.017167  0.228280   \n",
       "\n",
       "          6         7         8  ...       290       291       292       293  \\\n",
       "0  0.083481 -0.013165  0.014318  ... -0.008103  0.002998  0.009874  0.001091   \n",
       "1  0.083481 -0.013165  0.014318  ... -0.008103  0.002998  0.009874  0.001091   \n",
       "2  0.002031 -0.009363 -0.038313  ...  0.037275 -0.041498  0.001673  0.018245   \n",
       "3  0.002031 -0.009363 -0.038313  ...  0.037275 -0.041498  0.001673  0.018245   \n",
       "4  0.007839 -0.026089  0.005531  ... -0.007130  0.042597 -0.007180 -0.007903   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0  0.006758  0.000884 -0.007504 -0.003493  0.002939  0.003710  \n",
       "1  0.006758  0.000884 -0.007504 -0.003493  0.002939  0.003710  \n",
       "2  0.020412  0.019159  0.008809 -0.078762 -0.028517 -0.029286  \n",
       "3  0.020412  0.019159  0.008809 -0.078762 -0.028517 -0.029286  \n",
       "4  0.018143  0.023752  0.012634 -0.000541 -0.006356  0.012804  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_heads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28448, 300])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_heads_tensor = torch.tensor(positive_heads.drop('head',axis=1).values)\n",
    "positive_heads_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28448, 300])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_modifiers_tensor = torch.tensor(positive_modifiers.drop('modifier',axis=1).values)\n",
    "positive_modifiers_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28448])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_Y=torch.ones(positive_modifiers_tensor.shape[0])\n",
    "positive_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28448, 600])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_class=torch.cat((positive_modifiers_tensor, positive_heads_tensor), 1)\n",
    "positive_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_df_creator(file):\n",
    "    pkl_file=pkl.load( open(file,'rb'))\n",
    "    df=pd.DataFrame(pkl_file)\n",
    "    \n",
    "    df.columns=['modifier','head']\n",
    "    negative_heads=pd.merge(df.drop('modifier',axis=1),heads.reset_index(),on=[\"head\"])\n",
    "    negative_modifiers=pd.merge(df.drop('head',axis=1),modifiers.reset_index(),on=[\"modifier\"])\n",
    "    negative_heads_tensor = torch.tensor(negative_heads.drop('head',axis=1).values)\n",
    "    negative_modifiers_tensor = torch.tensor(negative_modifiers.drop('modifier',axis=1).values)\n",
    "\n",
    "    negative_Y=torch.zeros(negative_modifiers_tensor.shape[0])\n",
    "    negative_class=torch.cat((negative_modifiers_tensor, negative_heads_tensor), 1)\n",
    "\n",
    "    return negative_class,negative_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_joiner(files):\n",
    "    tensor_list=[]\n",
    "    for file in files:\n",
    "        negative_class,negative_Y=neg_df_creator(file)\n",
    "        X=torch.cat((positive_class, negative_class), 0)\n",
    "        Y=torch.cat((positive_Y,negative_Y),0)\n",
    "        tensor_list.append([X,Y])\n",
    "    \n",
    "    return tensor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt_modifier_files=[]\n",
    "for file in glob.glob(\"/data/dharp/compounding/datasets/corrupt_modifier*\"):\n",
    "    corrupt_modifier_files.append(file)\n",
    "corrupt_modifiers=tensor_joiner(corrupt_modifier_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt_head_files=[]\n",
    "for file in glob.glob(\"/data/dharp/compounding/datasets/corrupt_head*\"):\n",
    "    corrupt_head_files.append(file)\n",
    "corrupt_heads=tensor_joiner(corrupt_head_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 600\n",
    "hidden_size = 300\n",
    "num_classes = 2\n",
    "num_epochs = 50\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes,bias=False)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def looper(datasets):\n",
    "    total_accuracy=[]\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        X=dataset[0]\n",
    "        Y=dataset[1]\n",
    "        n = len(X)  # how many total elements you have\n",
    "        n_test = int( n * .2 )  # number of test/val elements\n",
    "        n_train = n - n_test\n",
    "        idx = list(range(n))  # indices to all elements\n",
    "        random.shuffle(idx)  # in-place shuffle the indices to facilitate random splitting\n",
    "        train_idx = idx[:n_train]\n",
    "        test_idx = idx[n_train:]\n",
    "        trX=X[train_idx].float().to(device)\n",
    "        teX=X[test_idx].float().to(device)\n",
    "\n",
    "        trY=Y[train_idx].long().to(device)\n",
    "        teY=Y[test_idx].long().to(device)\n",
    "        model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        n_examples=trX.shape[0]\n",
    "        for i in range(num_epochs):\n",
    "\n",
    "            cost = 0.\n",
    "\n",
    "            num_batches = n_examples // batch_size\n",
    "            for k in range(num_batches):\n",
    "                start, end = k * batch_size, (k + 1) * batch_size\n",
    "                outputs = model(trX[start:end])\n",
    "                loss = criterion(outputs, trY[start:end])\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            #if (k+1) % 100 == 0:\n",
    "            #print ('Epoch [{}/{}], Loss: {:.4f}'.format(i+1, num_epochs, loss.item()))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            correct=0\n",
    "            total=0\n",
    "            outputs = model(teX)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += teY.size(0)\n",
    "            correct += (predicted == teY).sum().item()\n",
    "        curr_acc=100 * correct / total\n",
    "        print(curr_acc)\n",
    "        total_accuracy.append(curr_acc)\n",
    "    return total_accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.2059056156077\n",
      "82.82801652166272\n",
      "82.704982863169\n",
      "82.14254328148344\n",
      "83.13560066789701\n",
      "82.47649178310924\n",
      "82.27436505844099\n",
      "82.50285613850075\n",
      "82.90710958783724\n",
      "82.67861850777749\n"
     ]
    }
   ],
   "source": [
    "cor_head_acc=looper(corrupt_heads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "82.91589770630108\n",
    "83.12681254943317\n",
    "82.59952544160295\n",
    "82.76649969241585\n",
    "83.14438878636084\n",
    "83.05650760172247\n",
    "82.90710958783724\n",
    "83.22348185253537\n",
    "82.67861850777749\n",
    "82.74892345548818"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.69"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(cor_head_acc),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.std(cor_head_acc),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.50285613850075\n",
      "82.6610422708498\n",
      "82.50285613850075\n",
      "81.52737498901485\n",
      "83.08287195711398\n",
      "82.27436505844099\n",
      "83.14438878636084\n",
      "82.4677036646454\n",
      "83.06529572018631\n",
      "82.26557693997715\n"
     ]
    }
   ],
   "source": [
    "cor_mod_acc=looper(corrupt_modifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "82.88074523244573\n",
    "83.40803234027595\n",
    "82.29194129536866\n",
    "81.87889972756832\n",
    "82.72255910009667\n",
    "82.21284822919412\n",
    "82.45891554618156\n",
    "82.5643729677476\n",
    "82.6610422708498\n",
    "82.3007294138325"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.55"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(cor_mod_acc),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.std(cor_mod_acc),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
