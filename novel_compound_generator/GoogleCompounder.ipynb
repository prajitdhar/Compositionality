{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from os import listdir\n",
    "from os.path import isfile, join,getsize\n",
    "import glob\n",
    "import time\n",
    "import random\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "#from scipy.interpolate import interp1d\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "import pickle as pkl\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import dask.array as da\n",
    "#from sklearn.decomposition import PCA,TruncatedSVD,NMF\n",
    "import dask.dataframe as dd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=ResourceWarning)\n",
    "np.random.seed(seed=1991)\n",
    "import feather\n",
    "import tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54400,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modifiers_list=pd.read_csv(\"/data/dharp/compounding/datasets/modifiers_reduced.csv\",delimiter=\"\\t\",usecols =[0])\n",
    "modifiers_list=modifiers_list.modifier.unique()\n",
    "modifiers_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53466,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heads_list=pd.read_csv(\"/data/dharp/compounding/datasets/heads_reduced.csv\",delimiter=\"\\t\",usecols =[0])\n",
    "heads_list=heads_list['head'].unique()\n",
    "heads_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83254,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_list=np.union1d(modifiers_list, heads_list)\n",
    "words_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83254"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list=[]\n",
    "for word in words_list:\n",
    "    word_list.append(word+\"oun\")\n",
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = [f for f in glob.glob(\"/data/dharp/compounding/datasets/entire_df_*_.h5\") if isfile(join(\"/data/dharp/compounding/datasets/\", f))]\n",
    "files=[]\n",
    "for f in input_files:\n",
    "    files.append(f)\n",
    "np.random.shuffle(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_to_us=pd.read_excel(\"Book.xlsx\")\n",
    "br_to_us_dict=dict(zip(br_to_us.UK.tolist(),br_to_us.US.tolist()))\n",
    "\n",
    "contextwords_df=pd.read_csv(\"contexts.csv\",sep=\"\\t\")\n",
    "contextwords=contextwords_df.context.tolist()\n",
    "\n",
    "\n",
    "adv_dict=dict(zip(['adv'],['r']))\n",
    "adv_replacement={'context_pos':adv_dict}\n",
    "spelling_replacement={'context':br_to_us_dict,'modifier':br_to_us_dict,'head':br_to_us_dict,'word':br_to_us_dict}\n",
    "\n",
    "\n",
    "pos_replacement={'pos':dict(zip([\"noun\",\"verb\",\"adj\"],['n','v','a']))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@da.as_gufunc(signature=\"(i)->()\", output_dtypes=str, vectorize=True)\n",
    "def lemma_maker(x, y):\n",
    "    return lemmatizer.lemmatize(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relemjoin(df,col_name,lemmatize=True):\n",
    "    new_col=col_name.split('_')[0]\n",
    "    new_col_pos=new_col[0]+\"_pos\"\n",
    "    df[new_col]=df[col_name].str.split('_', 1).str[0]\n",
    "    df[new_col_pos]=\"n\"\n",
    "    if lemmatize==True:\n",
    "        df[new_col]=np.vectorize(lemma_maker)(df[new_col], df[new_col_pos])\n",
    "    df[new_col]=df[new_col]+\"_n\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syntactic_reducer(df,align,level=None):\n",
    "    if len(df) == 0:\n",
    "        print(\"Am here\")\n",
    "        return df\n",
    "    if align==\"right\":\n",
    "        if level==\"word\":\n",
    "            #t1=time.time()\n",
    "            df=df.loc[df.fivegram_pos.str.match(r'^[-a-z]+_noun\\s+[-a-z]+_.+\\s+[-a-z]+_.+\\s+[-a-z]+_.+\\s+[-a-z]+_.+$')]\n",
    "            if len(df) == 0:\n",
    "                return df\n",
    "            \n",
    "            df['word_pos'],df['r1_pos'],df['r2_pos'],df['r3_pos'],_=df['fivegram_pos'].str.split(r'\\s+').str\n",
    "            #df=df.query('word_pos == @word_list')\n",
    "            df=relemjoin(df,'word_pos')\n",
    "            df=pd.melt(df,id_vars=['word','decade','count'],value_vars=['r1_pos','r2_pos','r3_pos'])\n",
    "            #print(time.time()-t1)\n",
    "            return df\n",
    "        else:\n",
    "            phrases=df.loc[df.fivegram_pos.str.match(r'^[-a-z]+_noun\\s+[-a-z]+_noun\\s+[-a-z]+_.+\\s+[-a-z]+_.+\\s+[-a-z]+_.+$')]\n",
    "            cdsm=phrases.loc[~phrases.fivegram_pos.str.match(r'^[-a-z]+_noun\\s+[-a-z]+_noun\\s+[a-z-]+_noun\\s+[a-z-]+_.+\\s+[a-z-]+_.+$')]\n",
    "\n",
    "            try:\n",
    "                phrases['modifier_pos'],phrases['head_pos'],phrases['r1_pos'],phrases['r2_pos'],phrases['r3_pos']=phrases['fivegram_pos'].str.split(r'\\s+').str\n",
    "                cdsm['modifier_pos'],cdsm['head_pos'],cdsm['r1_pos'],cdsm['r2_pos'],cdsm['r3_pos']=cdsm['fivegram_pos'].str.split(r'\\s+').str\n",
    "            except ValueError:\n",
    "                phrases=pd.DataFrame()\n",
    "                compounds=pd.DataFrame()\n",
    "                modifiers=pd.DataFrame()\n",
    "                heads=pd.DataFrame()\n",
    "                return phrases,compounds,modifiers,heads\n",
    "            \n",
    "            phrases=relemjoin(phrases,'modifier_pos',lemmatize=False)\n",
    "            phrases=relemjoin(phrases,'head_pos')\n",
    "            cdsm=relemjoin(cdsm,'modifier_pos',lemmatize=False)\n",
    "            cdsm=relemjoin(cdsm,'head_pos')\n",
    "            \n",
    "            phrases=pd.melt(phrases,id_vars=['modifier','head','decade','count'],value_vars=['r1_pos','r2_pos','r3_pos'])\n",
    "            compounds=pd.melt(cdsm,id_vars=['modifier','head','decade','count'],value_vars=['r1_pos','r2_pos','r3_pos'])\n",
    "            modifiers=pd.melt(cdsm,id_vars=['modifier','decade','count'],value_vars=['head','r1_pos','r2_pos'])\n",
    "            heads=pd.melt(cdsm,id_vars=['head','decade','count'],value_vars=['modifier','r1_pos','r2_pos','r3_pos'])\n",
    "\n",
    "            return phrases,compounds,modifiers,heads\n",
    "            \n",
    "            \n",
    "    elif align==\"mid1\":\n",
    "        if level==\"word\":\n",
    "            df=df.loc[df.fivegram_pos.str.match(r'^[a-z-]+_.+\\s+[a-z-]+_noun\\s+[a-z-]+_.+\\s+[a-z-]+_.+\\s+[a-z-]+_.+$')]\n",
    "            if len(df) == 0:\n",
    "                return df\n",
    "            \n",
    "            df['l1_pos'],df['word_pos'],df['r1_pos'],df['r2_pos'],df['r3_pos']=df['fivegram_pos'].str.split(r'\\s+').str\n",
    "            df=relemjoin(df,'word_pos')\n",
    "            df=pd.melt(df,id_vars=['word','decade','count'],value_vars=['l1_pos','r1_pos','r2_pos','r3_pos'])\n",
    "            return df\n",
    "        else:\n",
    "            phrases=df.loc[df.fivegram_pos.str.match(r'^[a-z-]+_.+\\s+[a-z-]+_noun\\s+[a-z-]+_noun\\s+[a-z-]+_.+\\s+[a-z-]+_.+$')]\n",
    "            cdsm=phrases.loc[~phrases.fivegram_pos.str.match(r'^[a-z-]+_noun\\s+[a-z-]+_noun\\s+[a-z-]+_noun\\s+[a-z-]+_noun\\s+[a-z-]+_.+$')]\n",
    "\n",
    "            try:\n",
    "                phrases['l1_pos'],phrases['modifier_pos'],phrases['head_pos'],phrases['r1_pos'],phrases['r2_pos']=phrases['fivegram_pos'].str.split(r'\\s+').str\n",
    "                cdsm['l1_pos'],cdsm['modifier_pos'],cdsm['head_pos'],cdsm['r1_pos'],cdsm['r2_pos']=cdsm['fivegram_pos'].str.split(r'\\s+').str\n",
    "            except ValueError:\n",
    "                phrases=pd.DataFrame()\n",
    "                compounds=pd.DataFrame()\n",
    "                modifiers=pd.DataFrame()\n",
    "                heads=pd.DataFrame()\n",
    "                return phrases,compounds,modifiers,heads\n",
    "            \n",
    "            phrases=relemjoin(phrases,'modifier_pos',lemmatize=False)\n",
    "            phrases=relemjoin(phrases,'head_pos')\n",
    "            cdsm=relemjoin(cdsm,'modifier_pos',lemmatize=False)\n",
    "            cdsm=relemjoin(cdsm,'head_pos')\n",
    "            \n",
    "            phrases=pd.melt(phrases,id_vars=['modifier','head','decade','count'],value_vars=['l1_pos','r1_pos','r2_pos'])\n",
    "            compounds=pd.melt(cdsm,id_vars=['modifier','head','decade','count'],value_vars=['l1_pos','r1_pos','r2_pos'])\n",
    "            modifiers=pd.melt(cdsm,id_vars=['modifier','decade','count'],value_vars=['head','l1_pos','r1_pos','r2_pos'])\n",
    "            heads=pd.melt(cdsm,id_vars=['head','decade','count'],value_vars=['modifier','l1_pos','r1_pos','r2_pos'])\n",
    "            return phrases,compounds,modifiers,heads\n",
    "    \n",
    "            \n",
    "    elif align==\"mid2\":\n",
    "        if level==\"word\":\n",
    "            df=df.loc[df.fivegram_pos.str.match(r'^[a-z-]+_.+\\s+[a-z-]+_.+\\s+[a-z-]+_noun\\s+[a-z-]+_.+\\s+[a-z-]+_.+$')]\n",
    "            if len(df) == 0:\n",
    "                return df\n",
    "            \n",
    "            df['l1_pos'],df['l2_pos'],df['word_pos'],df['r1_pos'],df['r2_pos']=df['fivegram_pos'].str.split(r'\\s+').str\n",
    "            df=relemjoin(df,'word_pos')\n",
    "            df=pd.melt(df,id_vars=['word','decade','count'],value_vars=['l1_pos','l2_pos','r1_pos','r2_pos'])\n",
    "            return df\n",
    "        else:\n",
    "            \n",
    "            phrases=df.loc[df.fivegram_pos.str.match(r'^[a-z-]+_.+\\s+[a-z-]+_.+\\s+[a-z-]+_noun\\s+[a-z-]+_noun\\s+[a-z-]+_.+$')]\n",
    "            cdsm=phrases.loc[~phrases.fivegram_pos.str.match(r'^[a-z-]+_.+\\s+[a-z-]+_noun\\s+[a-z-]+_noun\\s+[a-z-]+_noun\\s+[a-z-]+_noun$')]\n",
    "\n",
    "            try:\n",
    "                phrases['l1_pos'],phrases['l2_pos'],phrases['modifier_pos'],phrases['head_pos'],phrases['r1_pos']=phrases['fivegram_pos'].str.split(r'\\s+').str\n",
    "                cdsm['l1_pos'],cdsm['l2_pos'],cdsm['modifier_pos'],cdsm['head_pos'],cdsm['r1_pos']=cdsm['fivegram_pos'].str.split(r'\\s+').str\n",
    "            except ValueError:\n",
    "                phrases=pd.DataFrame()\n",
    "                compounds=pd.DataFrame()\n",
    "                modifiers=pd.DataFrame()\n",
    "                heads=pd.DataFrame()\n",
    "                return phrases,compounds,modifiers,heads\n",
    "            \n",
    "            phrases=relemjoin(phrases,'modifier_pos',lemmatize=False)\n",
    "            phrases=relemjoin(phrases,'head_pos')\n",
    "            cdsm=relemjoin(cdsm,'modifier_pos',lemmatize=False)\n",
    "            cdsm=relemjoin(cdsm,'head_pos')\n",
    "            \n",
    "            phrases=pd.melt(phrases,id_vars=['modifier','head','decade','count'],value_vars=['l1_pos','l2_pos','r1_pos'])\n",
    "            compounds=pd.melt(cdsm,id_vars=['modifier','head','decade','count'],value_vars=['l1_pos','l2_pos','r1_pos'])\n",
    "            modifiers=pd.melt(cdsm,id_vars=['modifier','decade','count'],value_vars=['head','l1_pos','l2_pos','r1_pos'])\n",
    "            heads=pd.melt(cdsm,id_vars=['head','decade','count'],value_vars=['modifier','l1_pos','l2_pos','r1_pos'])\n",
    "            return phrases,compounds,modifiers,heads\n",
    "            \n",
    "            \n",
    "    elif align==\"mid3\":\n",
    "        df=df.loc[df.fivegram_pos.str.match(r'^[a-z-]+_.+\\s+[a-z-]+_.+\\s+[a-z-]+_.+\\s+[a-z-]+_noun\\s+[a-z-]+_.+$')]\n",
    "        if len(df)==0:\n",
    "            return df\n",
    "\n",
    "        df['l1_pos'],df['l2_pos'],df['word_pos'],df['r1_pos'],df['r2_pos']=df['fivegram_pos'].str.split(r'\\s+').str\n",
    "        df=relemjoin(df,'word_pos')\n",
    "        df=pd.melt(df,id_vars=['word','decade','count'],value_vars=['l1_pos','l2_pos','r1_pos','r2_pos'])\n",
    "        return df\n",
    "        \n",
    "    elif align==\"left\":\n",
    "        \n",
    "        if level==\"word\":\n",
    "            df=df.loc[df.fivegram_pos.str.match(r'^[a-z-]+_.+\\s+[a-z-]+_.+\\s+[a-z-]+_.+\\s+[a-z-]+_.+\\s+[a-z-]+_noun$')]\n",
    "            if len(df) == 0:\n",
    "                return df\n",
    "            _,df['l1_pos'],df['l2_pos'],df['l3_pos'],df['word_pos']=df['fivegram_pos'].str.split(r'\\s+').str\n",
    "            df=relemjoin(df,'word_pos')\n",
    "            df=pd.melt(df,id_vars=['word','decade','count'],value_vars=['l1_pos','l2_pos','l3_pos'])\n",
    "            return df\n",
    "        else:\n",
    "            phrases=df.loc[df.fivegram_pos.str.match(r'^[a-z-]+_.+\\s+[a-z-]+_.+\\s+[a-z-]+_.+\\s+[a-z-]+_noun\\s+[a-z-]+_noun$')]\n",
    "            cdsm=phrases.loc[~phrases.fivegram_pos.str.match(r'^[a-z-]+_.+\\s+[a-z-]+_.+\\s+[a-z-]+_noun\\s+[a-z-]+_noun\\s+[a-z-]+_noun$')]\n",
    "            \n",
    "            try:\n",
    "                phrases['l1_pos'],phrases['l2_pos'],phrases['l3_pos'],phrases['modifier_pos'],phrases['head_pos']=phrases['fivegram_pos'].str.split(r'\\s+').str\n",
    "                cdsm['l1_pos'],cdsm['l2_pos'],cdsm['l3_pos'],cdsm['modifier_pos'],cdsm['head_pos']=cdsm['fivegram_pos'].str.split(r'\\s+').str\n",
    "            except ValueError:\n",
    "                phrases=pd.DataFrame()\n",
    "                compounds=pd.DataFrame()\n",
    "                modifiers=pd.DataFrame()\n",
    "                heads=pd.DataFrame()\n",
    "                return phrases,compounds,modifiers,heads\n",
    "            \n",
    "            phrases=relemjoin(phrases,'modifier_pos',lemmatize=False)\n",
    "            phrases=relemjoin(phrases,'head_pos')\n",
    "            cdsm=relemjoin(cdsm,'modifier_pos',lemmatize=False)\n",
    "            cdsm=relemjoin(cdsm,'head_pos')\n",
    "            \n",
    "            phrases=pd.melt(phrases,id_vars=['modifier','head','decade','count'],value_vars=['l1_pos','l2_pos','l3_pos'])\n",
    "            compounds=pd.melt(cdsm,id_vars=['modifier','head','decade','count'],value_vars=['l1_pos','l2_pos','l3_pos'])\n",
    "            modifiers=pd.melt(cdsm,id_vars=['modifier','decade','count'],value_vars=['head','l1_pos','l2_pos','l3_pos'])\n",
    "            heads=pd.melt(cdsm,id_vars=['head','decade','count'],value_vars=['modifier','l1_pos','l2_pos','l3_pos'])\n",
    "            return phrases,compounds,modifiers,heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_reducer(df):\n",
    "    if len(df)==0:\n",
    "        return df\n",
    "    df[\"variable\"]=df[\"variable\"].str.replace(r\"_pos\",\"\")\n",
    "    df[\"context\"],df[\"context_pos\"]=df['value'].str.split('_', 1).str\n",
    "    df.replace(spelling_replacement,inplace=True)\n",
    "    df=df.loc[df.context_pos.isin([\"noun\",\"adj\",\"adv\",\"verb\"])]\n",
    "    df.replace(adv_replacement,inplace=True)\n",
    "    df['context_pos']=df['context_pos'].str[0]\n",
    "    if len(df)==0:\n",
    "        return df\n",
    "    df['context']=np.vectorize(lemma_maker)(df['context'], df['context_pos'])\n",
    "    df['context']=df['context']+\"_\"+df['context_pos']\n",
    "    df.query('context in @contextwords',inplace=True)\n",
    "    #df.reset_index(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdsm_word_reducer(df):\n",
    "    rightgram=syntactic_reducer(df,align=\"right\",level=\"word\")\n",
    "    rightgram=context_reducer(rightgram)\n",
    "    \n",
    "    mid1gram=syntactic_reducer(df,align=\"mid1\",level=\"word\")\n",
    "    mid1gram=context_reducer(mid1gram)\n",
    "    \n",
    "    mid2gram=syntactic_reducer(df,align=\"mid2\",level=\"word\")\n",
    "    mid2gram=context_reducer(mid2gram)\n",
    "    \n",
    "    mid3gram=syntactic_reducer(df,align=\"mid3\",level=\"word\")\n",
    "    mid3gram=context_reducer(mid3gram)\n",
    "    \n",
    "    leftgram=syntactic_reducer(df,align=\"left\",level=\"word\")\n",
    "    leftgram=context_reducer(leftgram)    \n",
    "    \n",
    "    words_df=pd.concat([rightgram,mid1gram,mid2gram,mid3gram,leftgram],ignore_index=True)\n",
    "    words_df.dropna(inplace=True)\n",
    "    words_df=words_df.query('word in @words_list')\n",
    "    words_df=words_df.groupby(['word','context','decade'])['count'].sum().to_frame()\n",
    "    words_df.reset_index(inplace=True)\n",
    "    words_df.decade=words_df.decade.astype(\"int32\")\n",
    "    return words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdsm_reducer(df):\n",
    "    phrase_rightgram,compound_rightgram,modifier_rightgram,head_rightgram=syntactic_reducer(df,align=\"right\")\n",
    "    phrase_rightgram=context_reducer(phrase_rightgram)\n",
    "    compound_rightgram=context_reducer(compound_rightgram)\n",
    "    modifier_rightgram=context_reducer(modifier_rightgram)\n",
    "    head_rightgram=context_reducer(head_rightgram)\n",
    "\n",
    "\n",
    "    phrase_mid1gram,compound_mid1gram,modifier_mid1gram,head_mid1gram=syntactic_reducer(df,align=\"mid1\")\n",
    "    phrase_mid1gram=context_reducer(phrase_mid1gram)\n",
    "    compound_mid1gram=context_reducer(compound_mid1gram)\n",
    "    modifier_mid1gram=context_reducer(modifier_mid1gram)\n",
    "    head_mid1gram=context_reducer(head_mid1gram)\n",
    " \n",
    "\n",
    "    phrase_mid2gram,compound_mid2gram,modifier_mid2gram,head_mid2gram=syntactic_reducer(df,align=\"mid2\")\n",
    "    phrase_mid2gram=context_reducer(phrase_mid2gram)\n",
    "    compound_mid2gram=context_reducer(compound_mid2gram)\n",
    "    modifier_mid2gram=context_reducer(modifier_mid2gram)\n",
    "    head_mid2gram=context_reducer(head_mid2gram)\n",
    "    \n",
    "    phrase_leftgram,compound_leftgram,modifier_leftgram,head_leftgram=syntactic_reducer(df,align=\"left\")\n",
    "    phrase_leftgram=context_reducer(phrase_leftgram)\n",
    "    compound_leftgram=context_reducer(compound_leftgram)\n",
    "    modifier_leftgram=context_reducer(modifier_leftgram)\n",
    "    head_leftgram=context_reducer(head_leftgram)\n",
    "    \n",
    "    compounds=pd.concat([compound_rightgram,compound_mid1gram,compound_mid2gram,compound_leftgram],ignore_index=True)\n",
    "    modifiers=pd.concat([modifier_rightgram,modifier_mid1gram,modifier_mid2gram,modifier_leftgram],ignore_index=True)\n",
    "    heads=pd.concat([head_rightgram,head_mid1gram,head_mid2gram,head_leftgram],ignore_index=True)\n",
    "\n",
    "    phrases=pd.concat([phrase_rightgram,phrase_mid1gram,phrase_mid2gram,phrase_leftgram],ignore_index=True)\n",
    "    phrases.dropna(inplace=True)\n",
    "    phrases=phrases.groupby(['modifier','head','context','decade'])['count'].sum().to_frame()\n",
    "    phrases.reset_index(inplace=True)\n",
    "    phrases.decade=phrases.decade.astype(\"int32\")\n",
    "    \n",
    "    compounds.dropna(inplace=True)\n",
    "    compounds=compounds.groupby(['modifier','head','context','decade'])['count'].sum().to_frame()\n",
    "    compounds.reset_index(inplace=True)\n",
    "    compounds.decade=compounds.decade.astype(\"int32\")\n",
    "    \n",
    "    modifiers.dropna(inplace=True)\n",
    "    modifiers=modifiers.groupby(['modifier','context','decade'])['count'].sum().to_frame()\n",
    "    modifiers.reset_index(inplace=True)\n",
    "    modifiers.decade=modifiers.decade.astype(\"int32\")\n",
    "    \n",
    "    heads.dropna(inplace=True)\n",
    "    heads=heads.groupby(['head','context','decade'])['count'].sum().to_frame()\n",
    "    heads.reset_index(inplace=True)\n",
    "    heads.decade=heads.decade.astype(\"int32\")\n",
    "    return compounds,modifiers,heads,phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df, context_type=\"independant_word\",num_cores = 70):\n",
    "    num_partitions = num_cores\n",
    "    df_split = np.array_split(df, num_partitions)\n",
    "    print(\"Done splitting the datasets\")\n",
    "    pool = Pool(num_cores)\n",
    "\n",
    "    cur_time=time.time()\n",
    "    print(\"Starting parallelizing\")\n",
    "    if context_type==\"dependant\":\n",
    "\n",
    "        results=pool.map_async(cdsm_reducer,df_split)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        results=results.get()\n",
    "\n",
    "        \n",
    "        print(\"Done parallelizing\")\n",
    "        print(\"Total time taken\",round(time.time()-cur_time),\"secs\")\n",
    "        compound_list = [ result[0] for result in results]\n",
    "        compounds=pd.concat(compound_list,ignore_index=True)\n",
    "        compounds=compounds.groupby(['modifier','head','context','decade'])['count'].sum().to_frame()\n",
    "        compounds.reset_index(inplace=True)\n",
    "        \n",
    "        if not isfile(\"/data/dharp/compounding/datasets/compounds.csv\"):\n",
    "            compounds.to_csv(\"/data/dharp/compounding/datasets/compounds.csv\",sep=\"\\t\",index=False)\n",
    "        else:\n",
    "            compounds.to_csv(\"/data/dharp/compounding/datasets/compounds.csv\", mode='a',sep=\"\\t\", header=False,index=False)\n",
    "        \n",
    "        \n",
    "        modifier_list = [ result[1] for result in results]\n",
    "        modifiers=pd.concat(modifier_list,ignore_index=True)\n",
    "        modifiers=modifiers.groupby(['modifier','context','decade'])['count'].sum().to_frame()\n",
    "        modifiers.reset_index(inplace=True)\n",
    "\n",
    "        if not isfile(\"/data/dharp/compounding/datasets/modifiers.csv\"):\n",
    "            modifiers.to_csv(\"/data/dharp/compounding/datasets/modifiers.csv\",sep=\"\\t\",index=False)\n",
    "        else:\n",
    "            modifiers.to_csv(\"/data/dharp/compounding/datasets/modifiers.csv\", mode='a', header=False,index=False)\n",
    "        \n",
    "        head_list = [ result[2] for result in results]\n",
    "        heads=pd.concat(head_list,ignore_index=True)\n",
    "        heads=heads.groupby(['head','context','decade'])['count'].sum().to_frame()\n",
    "        heads.reset_index(inplace=True)\n",
    "\n",
    "        if not isfile(\"/data/dharp/compounding/datasets/heads.csv\"):\n",
    "            heads.to_csv(\"/data/dharp/compounding/datasets/heads.csv\",sep=\"\\t\",index=False)\n",
    "        else:\n",
    "            heads.to_csv(\"/data/dharp/compounding/datasets/heads.csv\", mode='a', header=False,index=False)\n",
    "            \n",
    "        phrase_list = [ result[3] for result in results]\n",
    "        phrases=pd.concat(phrase_list,ignore_index=True)\n",
    "        phrases=phrases.groupby(['modifier','head','context','decade'])['count'].sum().to_frame()\n",
    "        phrases.reset_index(inplace=True)\n",
    "        \n",
    "        if not isfile(\"/data/dharp/compounding/datasets/phrases.csv\"):\n",
    "            phrases.to_csv(\"/data/dharp/compounding/datasets/phrases.csv\",sep=\"\\t\",index=False)\n",
    "        else:\n",
    "            phrases.to_csv(\"/data/dharp/compounding/datasets/phrases.csv\", mode='a', header=False,index=False)\n",
    "\n",
    "    elif context_type==\"independant_word\":\n",
    "        words_list=[]\n",
    "        results=pool.map_async(cdsm_word_reducer,df_split)\n",
    "  \n",
    "        \n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        print(\"Done parallelizing\")\n",
    "        print(\"Total time taken\",round(time.time()-cur_time),\"secs\")\n",
    "        word_list=results.get()\n",
    "        words = pd.concat(words_list,ignore_index=True)\n",
    "        words=words.groupby(['word','context','decade'])['count'].sum().to_frame()\n",
    "        words.reset_index(inplace=True)\n",
    "        \n",
    "                \n",
    "        if not isfile(\"/data/dharp/compounding/datasets/words.csv\"):\n",
    "            words.to_csv(\"/data/dharp/compounding/datasets/words.csv\",sep=\"\\t\",index=False)\n",
    "        else:\n",
    "            words.to_csv(\"/data/dharp/compounding/datasets/words.csv\", mode='a',sep=\"\\t\", header=False,index=False)\n",
    "        \n",
    "    print(\"Done concatenations \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pkl_reader(files,size=None):\n",
    "    cur_time=time.time()\n",
    "    print(\"Reading the pickle files\")\n",
    "    pkl_list=[]\n",
    "    if size is None:\n",
    "        for f in files:\n",
    "            temp_df=pd.read_pickle(f)\n",
    "            if temp_df.empty==True:\n",
    "                print(\"File \",f,\" is empty\")\n",
    "                continue\n",
    "            pkl_list.append(temp_df)\n",
    "    else:\n",
    "        total_size=0\n",
    "        for f in files:\n",
    "            if total_size>size:\n",
    "                break\n",
    "            temp_df=pd.read_pickle(f)\n",
    "            if temp_df.empty==True:\n",
    "                print(\"File \",f,\" is empty\")\n",
    "                continue\n",
    "            total_size+=temp_df.shape[0]\n",
    "            pkl_list.append(temp_df)\n",
    "    print(\"Done reading the files \\n\")\n",
    "    entire_df=pd.concat(pkl_list,ignore_index=True)\n",
    "    print(\"Done concatenating the datasets \\n\")\n",
    "    print(\"Total time taken\",round(time.time()-cur_time),\"secs \\n\")\n",
    "    return entire_df.head(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_assign(df,split_col,splitter,col_names):\n",
    "    temp_cols=df[split_col].str.split(splitter,len(col_names)).str\n",
    "    df = df.assign(**{k:temp_cols[i] for i,k in enumerate(col_names)})\n",
    "    #df.drop(split_col,axis=1,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "chunk_size=200_000_000\n",
    "file_id=0\n",
    "for start in range(0, entire_df.shape[0], chunk_size):\n",
    "    entire_df.iloc[start:start + chunk_size].to_hdf('/data/dharp/compounding/datasets/entire_df_'+str(file_id)+'.h5', key='df', format='fixed', complevel=9, complib='zlib')\n",
    "    file_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/dharp/compounding/datasets/entire_df_0_.h5 is read in\n",
      "Done splitting the datasets\n",
      "Starting parallelizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-242:\n",
      "Process ForkPoolWorker-237:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-243:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-239:\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkPoolWorker-244:\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-57-dbb213186c1d>\", line 3, in cdsm_word_reducer\n",
      "    rightgram=context_reducer(rightgram)\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-56-4e9c8604ca96>\", line 6, in context_reducer\n",
      "    df.replace(spelling_replacement,inplace=True)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py\", line 3798, in replace\n",
      "    method=method)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5802, in replace\n",
      "    limit=limit, regex=regex)\n",
      "  File \"<ipython-input-57-dbb213186c1d>\", line 3, in cdsm_word_reducer\n",
      "    rightgram=context_reducer(rightgram)\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py\", line 3798, in replace\n",
      "    method=method)\n",
      "  File \"<ipython-input-56-4e9c8604ca96>\", line 6, in context_reducer\n",
      "    df.replace(spelling_replacement,inplace=True)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5821, in replace\n",
      "    regex=regex)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py\", line 3798, in replace\n",
      "    method=method)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/series.py\", line 3432, in replace\n",
      "    regex=regex, method=method)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5802, in replace\n",
      "    limit=limit, regex=regex)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py\", line 3798, in replace\n",
      "    method=method)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5821, in replace\n",
      "    regex=regex)\n",
      "  File \"<ipython-input-57-dbb213186c1d>\", line 3, in cdsm_word_reducer\n",
      "    rightgram=context_reducer(rightgram)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/series.py\", line 3432, in replace\n",
      "    regex=regex, method=method)\n",
      "  File \"<ipython-input-56-4e9c8604ca96>\", line 6, in context_reducer\n",
      "    df.replace(spelling_replacement,inplace=True)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5851, in replace\n",
      "    regex=regex)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5851, in replace\n",
      "    regex=regex)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-52c37129aae3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtmp_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmp_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10_000_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#print(\"Compounds and Phrases\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mparallelize_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontext_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"independant_word\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_cores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done writing to files\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-2a06f27ab04a>\u001b[0m in \u001b[0;36mparallelize_dataframe\u001b[0;34m(df, context_type, num_cores)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done parallelizing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total time taken\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcur_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"secs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'joining pool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCLOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/dharp/packages/miniconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/dharp/packages/miniconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 3754, in replace_list\n",
      "    mgr=mgr, convert=convert)\n",
      "  File \"<ipython-input-57-dbb213186c1d>\", line 3, in cdsm_word_reducer\n",
      "    rightgram=context_reducer(rightgram)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 3751, in replace_list\n",
      "    if b.dtype == np.object_:\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py\", line 3798, in replace\n",
      "    method=method)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 2440, in replace\n",
      "    convert=convert, mgr=mgr)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-56-4e9c8604ca96>\", line 6, in context_reducer\n",
      "    df.replace(spelling_replacement,inplace=True)\n",
      "Process ForkPoolWorker-240:\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5802, in replace\n",
      "    limit=limit, regex=regex)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 352, in dtype\n",
      "    @property\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 797, in replace\n",
      "    mask = missing.mask_missing(values, to_replace)\n",
      "  File \"<ipython-input-57-dbb213186c1d>\", line 3, in cdsm_word_reducer\n",
      "    rightgram=context_reducer(rightgram)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py\", line 3798, in replace\n",
      "    method=method)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py\", line 3798, in replace\n",
      "    method=method)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-56-4e9c8604ca96>\", line 6, in context_reducer\n",
      "    df.replace(spelling_replacement,inplace=True)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/missing.py\", line 51, in mask_missing\n",
      "    mask = arr == x\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5802, in replace\n",
      "    limit=limit, regex=regex)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5821, in replace\n",
      "    regex=regex)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py\", line 3798, in replace\n",
      "    method=method)\n",
      "KeyboardInterrupt\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/series.py\", line 3432, in replace\n",
      "    regex=regex, method=method)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5802, in replace\n",
      "    limit=limit, regex=regex)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py\", line 3798, in replace\n",
      "    method=method)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5851, in replace\n",
      "    regex=regex)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 3754, in replace_list\n",
      "    mgr=mgr, convert=convert)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5821, in replace\n",
      "    regex=regex)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py\", line 3798, in replace\n",
      "    method=method)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/series.py\", line 3432, in replace\n",
      "    regex=regex, method=method)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 2440, in replace\n",
      "    convert=convert, mgr=mgr)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5821, in replace\n",
      "    regex=regex)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5851, in replace\n",
      "    regex=regex)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 802, in replace\n",
      "    blocks = self.putmask(mask, value, inplace=inplace)\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/series.py\", line 3432, in replace\n",
      "    regex=regex, method=method)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 969, in putmask\n",
      "    new_values = self.values if inplace else self.values.copy()\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 3754, in replace_list\n",
      "    mgr=mgr, convert=convert)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5851, in replace\n",
      "    regex=regex)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 2440, in replace\n",
      "    convert=convert, mgr=mgr)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 3754, in replace_list\n",
      "    mgr=mgr, convert=convert)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 797, in replace\n",
      "    mask = missing.mask_missing(values, to_replace)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/missing.py\", line 51, in mask_missing\n",
      "    mask = arr == x\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 2440, in replace\n",
      "    convert=convert, mgr=mgr)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "KeyboardInterrupt\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 802, in replace\n",
      "    blocks = self.putmask(mask, value, inplace=inplace)\n",
      "  File \"<ipython-input-57-dbb213186c1d>\", line 3, in cdsm_word_reducer\n",
      "    rightgram=context_reducer(rightgram)\n",
      "  File \"<ipython-input-56-4e9c8604ca96>\", line 6, in context_reducer\n",
      "    df.replace(spelling_replacement,inplace=True)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 969, in putmask\n",
      "    new_values = self.values if inplace else self.values.copy()\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py\", line 3798, in replace\n",
      "    method=method)\n",
      "KeyboardInterrupt\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5802, in replace\n",
      "    limit=limit, regex=regex)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py\", line 3798, in replace\n",
      "    method=method)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5821, in replace\n",
      "    regex=regex)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/series.py\", line 3432, in replace\n",
      "    regex=regex, method=method)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5851, in replace\n",
      "    regex=regex)\n",
      "Process ForkPoolWorker-241:\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 3754, in replace_list\n",
      "    mgr=mgr, convert=convert)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 2440, in replace\n",
      "    convert=convert, mgr=mgr)\n",
      "Process ForkPoolWorker-238:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 802, in replace\n",
      "    blocks = self.putmask(mask, value, inplace=inplace)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 969, in putmask\n",
      "    new_values = self.values if inplace else self.values.copy()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-57-dbb213186c1d>\", line 3, in cdsm_word_reducer\n",
      "    rightgram=context_reducer(rightgram)\n",
      "  File \"<ipython-input-56-4e9c8604ca96>\", line 6, in context_reducer\n",
      "    df.replace(spelling_replacement,inplace=True)\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py\", line 3798, in replace\n",
      "    method=method)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5802, in replace\n",
      "    limit=limit, regex=regex)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py\", line 3798, in replace\n",
      "    method=method)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5821, in replace\n",
      "    regex=regex)\n",
      "  File \"<ipython-input-57-dbb213186c1d>\", line 3, in cdsm_word_reducer\n",
      "    rightgram=context_reducer(rightgram)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/series.py\", line 3432, in replace\n",
      "    regex=regex, method=method)\n",
      "  File \"<ipython-input-56-4e9c8604ca96>\", line 6, in context_reducer\n",
      "    df.replace(spelling_replacement,inplace=True)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py\", line 3798, in replace\n",
      "    method=method)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5802, in replace\n",
      "    limit=limit, regex=regex)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py\", line 3798, in replace\n",
      "    method=method)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5851, in replace\n",
      "    regex=regex)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5821, in replace\n",
      "    regex=regex)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 3754, in replace_list\n",
      "    mgr=mgr, convert=convert)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/series.py\", line 3432, in replace\n",
      "    regex=regex, method=method)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 5851, in replace\n",
      "    regex=regex)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 3754, in replace_list\n",
      "    mgr=mgr, convert=convert)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 2440, in replace\n",
      "    convert=convert, mgr=mgr)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 802, in replace\n",
      "    blocks = self.putmask(mask, value, inplace=inplace)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 2440, in replace\n",
      "    convert=convert, mgr=mgr)\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 969, in putmask\n",
      "    new_values = self.values if inplace else self.values.copy()\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 802, in replace\n",
      "    blocks = self.putmask(mask, value, inplace=inplace)\n",
      "KeyboardInterrupt\n",
      "  File \"/data/dharp/packages/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 969, in putmask\n",
      "    new_values = self.values if inplace else self.values.copy()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "num_cores=8\n",
    "f = '/data/dharp/compounding/datasets/entire_df_0_.h5'\n",
    "print(f,'is read in')\n",
    "tmp_df=pd.read_hdf(f, key='df')\n",
    "tmp_df=tmp_df.head(10_000_000)\n",
    "#print(\"Compounds and Phrases\")\n",
    "parallelize_dataframe(tmp_df,context_type=\"independant_word\",num_cores=num_cores)\n",
    "print(\"Done writing to files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdsm_word_reducer(tmp_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
